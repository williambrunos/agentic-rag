{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NXlWRqFBH4d"
      },
      "source": [
        "## Creating the Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "teste\n"
          ]
        }
      ],
      "source": [
        "print(\"teste\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUPi5sjyCQp7",
        "outputId": "00cdba2c-246c-49a1-967c-2c6b34854dc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama_index in ./.venv/lib/python3.11/site-packages (0.12.32)\n",
            "Requirement already satisfied: datasets in ./.venv/lib/python3.11/site-packages (3.5.0)\n",
            "Requirement already satisfied: llama-index-llms-huggingface in ./.venv/lib/python3.11/site-packages (0.5.0)\n",
            "Requirement already satisfied: llama-index-retrievers-bm25 in ./.venv/lib/python3.11/site-packages (0.5.2)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from llama_index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in ./.venv/lib/python3.11/site-packages (from llama_index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.32 in ./.venv/lib/python3.11/site-packages (from llama_index) (0.12.32)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from llama_index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in ./.venv/lib/python3.11/site-packages (from llama_index) (0.6.11)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from llama_index) (0.3.38)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from llama_index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from llama_index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from llama_index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from llama_index) (0.4.7)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in ./.venv/lib/python3.11/site-packages (from llama_index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in ./.venv/lib/python3.11/site-packages (from llama_index) (3.9.1)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from datasets) (2.2.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in ./.venv/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in ./.venv/lib/python3.11/site-packages (from datasets) (3.11.18)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.venv/lib/python3.11/site-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in ./.venv/lib/python3.11/site-packages (from llama-index-llms-huggingface) (2.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in ./.venv/lib/python3.11/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.51.3)\n",
            "Requirement already satisfied: bm25s<0.3.0,>=0.2.0 in ./.venv/lib/python3.11/site-packages (from llama-index-retrievers-bm25) (0.2.12)\n",
            "Requirement already satisfied: pystemmer<3.0.0.0,>=2.2.0.1 in ./.venv/lib/python3.11/site-packages (from llama-index-retrievers-bm25) (2.2.0.3)\n",
            "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (1.15.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: openai>=1.14.0 in ./.venv/lib/python3.11/site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.75.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.32->llama_index) (2.0.40)\n",
            "Requirement already satisfied: banks<3.0.0,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (2.1.2)\n",
            "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (1.2.0)\n",
            "Requirement already satisfied: httpx in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (2.11.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in ./.venv/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (0.1.18)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./.venv/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (4.13.4)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in ./.venv/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in ./.venv/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in ./.venv/lib/python3.11/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.12)\n",
            "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama_index) (8.1.8)\n",
            "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.5.3)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in ./.venv/lib/python3.11/site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (1.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (7.0.0)\n",
            "Requirement already satisfied: griffe in ./.venv/lib/python3.11/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (1.7.2)\n",
            "Requirement already satisfied: platformdirs in ./.venv/lib/python3.11/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (4.3.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.7)\n",
            "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.32->llama_index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.32->llama_index) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.32->llama_index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.12 in ./.venv/lib/python3.11/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.12)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.32->llama_index) (3.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.32->llama_index) (3.26.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.0.2)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in ./.venv/lib/python3.11/site-packages (from llama-cloud-services>=0.6.12->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (1.1.0)\n",
            "Requirement already satisfied: colorama>=0.4 in ./.venv/lib/python3.11/site-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (0.4.6)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install llama_index datasets llama-index-llms-huggingface llama-index-retrievers-bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S1q2O_QBJam",
        "outputId": "a1936231-7a7a-4719-dd65-523676b6acbf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/william/repos/agentic-rag/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "from llama_index.core.schema import Document\n",
        "\n",
        "guest_dataset = datasets.load_dataset(\"agents-course/unit3-invitees\", split=\"train\")\n",
        "\n",
        "docs = [\n",
        "    Document(\n",
        "        text=\"\\n\".join([\n",
        "          f\"Name: {guest_dataset['name'][i]}\",\n",
        "          f\"Relation: {guest_dataset['relation'][i]}\",\n",
        "          f\"Description: {guest_dataset['description'][i]}\",\n",
        "          f\"Email: {guest_dataset['email'][i]}\"\n",
        "    ]),\n",
        "        metadata={\"name\": guest_dataset['name'][i]}\n",
        "    )\n",
        "     for i in range(len(guest_dataset))\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74cAndkQBBu3",
        "outputId": "1252aa10-7ea0-4bd7-a458-f5e26cc7c1d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(id_='caba66d7-75f2-4fe1-b10b-bc17f6a09978', embedding=None, metadata={'name': 'Ada Lovelace'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Name: Ada Lovelace\\nRelation: best friend\\nDescription: Lady Ada Lovelace is my best friend. She is an esteemed mathematician and friend. She is renowned for her pioneering work in mathematics and computing, often celebrated as the first computer programmer due to her work on Charles Babbage's Analytical Engine.\\nEmail: ada.lovelace@example.com\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScXqR2AICwMJ"
      },
      "source": [
        "## Building the retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOnSeBrPCx2j",
        "outputId": "a8abb65b-16ca-4427-ed1f-d121e558c2f3"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.retrievers.bm25 import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_defaults(nodes=docs)\n",
        "\n",
        "def get_guest_info_retriever(query: str) -> str:\n",
        "    \"\"\"Retrieves detailed information about gala guests based on their name or relation.\"\"\"\n",
        "    results = bm25_retriever.retrieve(query)\n",
        "    if results:\n",
        "        return \"\\n\\n\".join([doc.text for doc in results[:3]])\n",
        "    else:\n",
        "        return \"No matching guest information found.\"\n",
        "\n",
        "# Initialize the tool\n",
        "guest_info_tool = FunctionTool.from_defaults(get_guest_info_retriever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On3dQrWNDuFJ"
      },
      "source": [
        "## Building the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW3szcG9HROH",
        "outputId": "198e71b9-1c4d-4963-8d4e-31d38fb29381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-llms-huggingface-api in ./.venv/lib/python3.11/site-packages (0.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in ./.venv/lib/python3.11/site-packages (from llama-index-llms-huggingface-api) (0.30.2)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in ./.venv/lib/python3.11/site-packages (from llama-index-llms-huggingface-api) (0.12.32)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (6.0.2)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (4.13.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.11.18)\n",
            "Requirement already satisfied: banks<3.0.0,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.1.2)\n",
            "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.2.0)\n",
            "Requirement already satisfied: httpx in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.9.1)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.2.5)\n",
            "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.11.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.9.0)\n",
            "Requirement already satisfied: wrapt in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.20.0)\n",
            "Requirement already satisfied: griffe in ./.venv/lib/python3.11/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.7.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in ./.venv/lib/python3.11/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (4.3.7)\n",
            "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (8.1.8)\n",
            "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.26.1)\n",
            "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in ./.venv/lib/python3.11/site-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index-llms-huggingface-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-llms-ollama in ./.venv/lib/python3.11/site-packages (0.5.4)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.4 in ./.venv/lib/python3.11/site-packages (from llama-index-llms-ollama) (0.12.32)\n",
            "Requirement already satisfied: ollama>=0.4.3 in ./.venv/lib/python3.11/site-packages (from llama-index-llms-ollama) (0.4.8)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.11.18)\n",
            "Requirement already satisfied: banks<3.0.0,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.1.2)\n",
            "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2024.12.0)\n",
            "Requirement already satisfied: httpx in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.9.1)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.2.5)\n",
            "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.11.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.13.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.9.0)\n",
            "Requirement already satisfied: wrapt in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.20.0)\n",
            "Requirement already satisfied: griffe in ./.venv/lib/python3.11/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.7.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in ./.venv/lib/python3.11/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.3.7)\n",
            "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.9.0)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.0.8)\n",
            "Requirement already satisfied: idna in ./.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.14.0)\n",
            "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (8.1.8)\n",
            "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (25.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in ./.venv/lib/python3.11/site-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index-llms-ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_8UFAmxaDvYE",
        "outputId": "4f7f2808-cf5d-43d4-a00f-9369afe87509"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.agent.workflow import AgentWorkflow\n",
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "# Initialize the Hugging Face model\n",
        "llm = Ollama(\n",
        "        model=\"llama3.2\",\n",
        "        temperature=0.1,\n",
        "        request_timeout=120.0\n",
        "    )\n",
        "\n",
        "alfred = AgentWorkflow.from_tools_or_functions(\n",
        "    [guest_info_tool],\n",
        "    llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ© Alfred's Response:\n",
            "Lady Ada Lovelace was a mathematician and computer scientist who is widely recognized as the world's first computer programmer. She is best known for her work on Charles Babbage's proposed mechanical general-purpose computer, the Analytical Engine.\n",
            "\n",
            "In 1843, Ada Lovelace wrote a set of notes on the Analytical Engine, which included what is considered to be the first algorithm intended to be processed by a machine. Her notes were written in response to an article about the engine by Italian mathematician Luigi Menabrea, and they provided a detailed analysis of how the machine could be used to perform calculations and manipulate data.\n",
            "\n",
            "Ada Lovelace's work on the Analytical Engine was well ahead of its time, and it laid the foundation for modern computer science. She is often credited with recognizing the potential of machines to go beyond mere calculation and perform any task that could be expressed in a series of steps.\n",
            "\n",
            "Today, Ada Lovelace is celebrated as a pioneer in the field of computer science, and her legacy continues to inspire new generations of programmers and scientists.\n"
          ]
        }
      ],
      "source": [
        "# Example query Alfred might receive during the gala\n",
        "response = await alfred.run(\"Tell me about our guest named 'Lady Ada Lovelace'.\")\n",
        "\n",
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Giving Alfred access to the web"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-tools-duckduckgo in ./.venv/lib/python3.11/site-packages (0.3.0)\n",
            "Requirement already satisfied: duckduckgo-search<7.0.0,>=6.1.0 in ./.venv/lib/python3.11/site-packages (from llama-index-tools-duckduckgo) (6.4.2)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in ./.venv/lib/python3.11/site-packages (from llama-index-tools-duckduckgo) (0.12.32)\n",
            "Requirement already satisfied: click>=8.1.7 in ./.venv/lib/python3.11/site-packages (from duckduckgo-search<7.0.0,>=6.1.0->llama-index-tools-duckduckgo) (8.1.8)\n",
            "Requirement already satisfied: primp>=0.9.1 in ./.venv/lib/python3.11/site-packages (from duckduckgo-search<7.0.0,>=6.1.0->llama-index-tools-duckduckgo) (0.15.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (3.11.18)\n",
            "Requirement already satisfied: banks<3.0.0,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (2.1.2)\n",
            "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (2024.12.0)\n",
            "Requirement already satisfied: httpx in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (3.9.1)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (2.2.5)\n",
            "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (2.11.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (4.13.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (0.9.0)\n",
            "Requirement already satisfied: wrapt in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.20.0)\n",
            "Requirement already satisfied: griffe in ./.venv/lib/python3.11/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.7.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in ./.venv/lib/python3.11/site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (4.3.7)\n",
            "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (3.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (3.26.1)\n",
            "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (25.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in ./.venv/lib/python3.11/site-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-duckduckgo) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index-tools-duckduckgo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "g85L-BCADILy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Search Tool Response: Emmanuel Macron, born on December 21, 1977, is the current president of the French Republic.In office since May 14, 2017, he was re-elected on April 24, 2022 with 58.55% of the votes against his competitor Marine Le Pen. With a background in higher public service and investment banking, Macron approaches his mandate with a desire for change and innovation in various fields, including economics ...\n"
          ]
        }
      ],
      "source": [
        "from llama_index.tools.duckduckgo import DuckDuckGoSearchToolSpec\n",
        "from llama_index.core.tools import FunctionTool\n",
        "\n",
        "tool_spec = DuckDuckGoSearchToolSpec()\n",
        "search_tool = FunctionTool.from_defaults(tool_spec.duckduckgo_full_search)\n",
        "\n",
        "response = search_tool(\"Who's the current President of France?\")\n",
        "print(f\"ðŸ” Search Tool Response: {response.raw_output[-1]['body']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom weather search tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "i9_sRwK7DGn4"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from llama_index.core.tools import FunctionTool\n",
        "\n",
        "def get_weather_info(location: str) -> str:\n",
        "    \"\"\"Fetches dummy weather information for a given location.\"\"\"\n",
        "    # Dummy weather data\n",
        "    weather_conditions = [\n",
        "        {\"condition\": \"Rainy\", \"temp_c\": 15},\n",
        "        {\"condition\": \"Clear\", \"temp_c\": 25},\n",
        "        {\"condition\": \"Windy\", \"temp_c\": 20}\n",
        "    ]\n",
        "    # Randomly select a weather condition\n",
        "    data = random.choice(weather_conditions)\n",
        "    return f\"Weather in {location}: {data['condition']}, {data['temp_c']}Â°C\"\n",
        "\n",
        "# Initialize the tool\n",
        "weather_info_tool = FunctionTool.from_defaults(get_weather_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AI Builders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most downloaded model by facebook is facebook/esmfold_v1 with 22,216,629 downloads.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "from huggingface_hub import list_models\n",
        "\n",
        "def get_hub_stats(author: str) -> str:\n",
        "    \"\"\"Fetches the most downloaded model from a specific author on the Hugging Face Hub.\"\"\"\n",
        "    try:\n",
        "        # List models from the specified author, sorted by downloads\n",
        "        models = list(list_models(author=author, sort=\"downloads\", direction=-1, limit=1))\n",
        "\n",
        "        if models:\n",
        "            model = models[0]\n",
        "            return f\"The most downloaded model by {author} is {model.id} with {model.downloads:,} downloads.\"\n",
        "        else:\n",
        "            return f\"No models found for author {author}.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching models for {author}: {str(e)}\"\n",
        "\n",
        "hub_stats_tool = FunctionTool.from_defaults(get_hub_stats)\n",
        "\n",
        "print(hub_stats_tool(\"facebook\")) # Example: Get the most downloaded model by Facebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integrating Tools to Alfred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core.agent.workflow import AgentWorkflow\n",
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "llm = Ollama(\n",
        "        model=\"llama3.2\",\n",
        "        temperature=0.1,\n",
        "        request_timeout=120.0\n",
        "    )\n",
        "alfred = AgentWorkflow.from_tools_or_functions(\n",
        "    [guest_info_tool, search_tool, weather_info_tool, hub_stats_tool],\n",
        "    llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŒ¤ï¸ Alfred's Weather Response: The current weather in Paris is rainy with a temperature of 15Â°C (59Â°F). It's a good idea to carry an umbrella and wear waterproof clothing if you're planning to visit the city.\n"
          ]
        }
      ],
      "source": [
        "response = await alfred.run(\"What's the weather like in Paris?\")\n",
        "print(f\"ðŸŒ¤ï¸ Alfred's Weather Response: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ© Alfred's Response:\n",
            "Facebook is a social media platform where users can create profiles, connect with friends and family, share updates and photos, and join groups based on common interests.\n",
            "\n",
            "As for their most popular model, I couldn't find any specific information on a \"model\" associated with Facebook. However, the company has developed several products and technologies over the years, including:\n",
            "\n",
            "1. News Feed: a feature that displays a curated feed of posts from friends and pages you follow.\n",
            "2. Instagram: a photo and video-sharing platform acquired by Facebook in 2012.\n",
            "3. WhatsApp: a messaging app acquired by Facebook in 2014.\n",
            "\n",
            "These products have become incredibly popular among users, with billions of people using them every day.\n"
          ]
        }
      ],
      "source": [
        "response = await alfred.run(\"What is Facebook and what's their most popular model?\")\n",
        "\n",
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ© Alfred's Response:\n",
            "Lady Ada Lovelace (1815-1852) was a British mathematician and writer, often considered the world's first computer programmer. She was born Augusta Ada Byron, the daughter of the poet Lord George Gordon Byron and his wife Anne Isabella Milbanke.\n",
            "\n",
            "Ada's early life was marked by tragedy when her mother died when she was just eight years old. Her father abandoned the family, leaving them in poverty. To support herself, Ada took up music lessons and later became proficient in mathematics, a subject she found fascinating.\n",
            "\n",
            "In 1833, Ada met Augustus De Morgan, a mathematician who introduced her to Charles Babbage's proposed mechanical general-purpose computer, the Analytical Engine. This encounter sparked her interest in mathematics and computing, which would eventually become her life's work.\n",
            "\n",
            "Ada collaborated with Babbage on his engine design, writing notes and specifications for its operation. Her work on the Analytical Engine is considered the first algorithm intended to be processed by a machine, making her a pioneer in computer science.\n",
            "\n",
            "Throughout her life, Ada struggled with mental health issues and personal relationships. Despite these challenges, she continued to work on mathematics and computing, producing notable papers on the subject.\n",
            "\n",
            "Tragically, Ada died at the age of 36 due to complications from cancer. Her legacy as a mathematician and computer scientist has endured, inspiring generations of scientists, engineers, and programmers.\n",
            "\n",
            "Today, Lady Ada Lovelace is celebrated for her groundbreaking work in mathematics and computing, and her name has become synonymous with innovation and pioneering spirit.\n"
          ]
        }
      ],
      "source": [
        "query = \"Tell me about Lady Ada Lovelace. What's her background?\"\n",
        "response = await alfred.run(query)\n",
        "\n",
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response.response.blocks[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ© Alfred's Response:\n",
            "The current weather conditions in Paris are mostly clear with a temperature of 20Â°C (68Â°F). However, it's also quite windy, which might affect the stability and visibility of your fireworks display.\n",
            "\n",
            "Considering this, I would recommend taking necessary precautions to ensure the safety of your event. You may want to consider using wind-resistant fireworks or adjusting the timing of your display to minimize the impact of the wind.\n",
            "\n",
            "Additionally, you can check the forecast for any potential changes in the weather before the event. The Meteo France website provides up-to-date weather forecasts and warnings for Paris.\n",
            "\n",
            "Please let me know if there's anything else I can help with!\n"
          ]
        }
      ],
      "source": [
        "query = \"What's the weather like in Paris tonight? Will it be suitable for our fireworks display?\"\n",
        "response = await alfred.run(query)\n",
        "\n",
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ© Alfred's Response:\n",
            "It seems that I couldn't find any information on a specific model from Google. However, I can tell you about some of the most popular machine learning models used by Google in various applications.\n",
            "\n",
            "1. **BERT (Bidirectional Encoder Representations from Transformers)**: BERT is a pre-trained language model developed by Google that has achieved state-of-the-art results in many natural language processing tasks such as question answering, sentiment analysis, and text classification.\n",
            "2. **TensorFlow**: TensorFlow is an open-source machine learning framework developed by Google that allows developers to easily implement and deploy machine learning models.\n",
            "3. **Google Cloud AI Platform**: Google Cloud AI Platform is a fully managed platform for building, deploying, and managing machine learning models in the cloud.\n",
            "\n",
            "These are just a few examples of popular models and technologies used by Google. If you have any specific questions or would like more information on these topics, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "query = \"One of our guests is from Google. What can you tell me about their most popular model?\"\n",
        "response = await alfred.run(query)\n",
        "\n",
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ© Alfred's Response:\n",
            "It seems I have some unexpected guests. Let me try again.\n",
            "\n",
            "I've managed to arrange a meeting with Dr. Nikola Tesla regarding recent advancements in wireless energy. Before our conversation, let's review some key points about his work:\n",
            "\n",
            "*   Wireless power transmission using electromagnetic induction\n",
            "*   Patented a system for transmitting electrical energy wirelessly over long distances\n",
            "*   Experimented with various frequencies and resonance techniques to optimize efficiency\n",
            "\n",
            "Before meeting Dr. Tesla, you may want to consider the following topics to discuss during your conversation:\n",
            "\n",
            "1.  **Wireless Power Transmission**: Ask about his experiences with wireless power transmission, including any challenges he faced and how he overcame them.\n",
            "2.  **Applications of Wireless Energy**: Discuss potential applications for wireless energy, such as powering devices in remote areas or eliminating the need for cables.\n",
            "3.  **Future Research Directions**: Inquire about Dr. Tesla's thoughts on future research directions for wireless energy, including any potential breakthroughs or innovations he envisions.\n",
            "\n",
            "By being prepared and showing genuine interest in his work, you'll be able to have a productive and engaging conversation with Dr. Nikola Tesla.\n"
          ]
        }
      ],
      "source": [
        "query = \"I need to speak with Dr. Nikola Tesla about recent advancements in wireless energy. Can you help me prepare for this conversation?\"\n",
        "response = await alfred.run(query)\n",
        "\n",
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implementing memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ© Alfred's First Response:\n",
            "Lady Ada Lovelace (1815-1852) was a British mathematician and writer who is widely recognized as the world's first computer programmer. She is best known for her work on Charles Babbage's proposed mechanical general-purpose computer, the Analytical Engine.\n",
            "\n",
            "Lovelace was born Augusta Ada King, Countess of Lovelace, to Lord George Gordon Byron and Anne Isabella Milbanke. Her father was a famous poet, and her mother encouraged her interest in mathematics and science from an early age. Lovelace's mathematical abilities were evident from a young age, and she went on to study mathematics at the University of Cambridge.\n",
            "\n",
            "In 1843, Lovelace met Charles Babbage, who was working on his Analytical Engine project. Babbage showed her his designs for the machine, and Lovelace was fascinated by its potential. She wrote a set of notes on the engine, which included what is considered to be the first computer program.\n",
            "\n",
            "Lovelace's notes on the Analytical Engine were based on an Italian mathematician named Luigi Menabrea's paper on the subject. She added her own comments and insights, which were more extensive than Menabrea's original work. Her notes included a method for calculating Bernoulli numbers using the Analytical Engine.\n",
            "\n",
            "Lovelace's work on the Analytical Engine was groundbreaking because it demonstrated the potential of machines to perform calculations that would have been impossible for humans to do by hand. She also recognized the importance of programming and the need for a way to communicate instructions to machines.\n",
            "\n",
            "Despite her significant contributions to the field of computer science, Lovelace's life was cut short when she died of cancer at the age of 36. However, her work on the Analytical Engine and her notes on its capabilities have had a lasting impact on the development of computers.\n",
            "\n",
            "Today, Lady Ada Lovelace is celebrated as a pioneer in the field of computer science, and her legacy continues to inspire new generations of programmers and scientists.\n",
            "ðŸŽ© Alfred's Second Response:\n",
            "Unfortunately, I couldn't find any information on current projects that Lady Ada Lovelace is working on, as she passed away in 1852 and her work was done in the 19th century. However, her legacy continues to inspire researchers and scientists in the field of computer science.\n",
            "\n",
            "Some modern-day projects and initiatives that are inspired by Lady Ada Lovelace's work include:\n",
            "\n",
            "* The Ada Initiative: a non-profit organization dedicated to promoting women in technology and increasing diversity in the tech industry.\n",
            "* The Lovelace Medal: an award given annually by the IEEE Computer Society to recognize outstanding contributions to the field of computer science, particularly in the area of artificial intelligence.\n",
            "* The Ada Lovelace Day: an annual event held on October 10th to celebrate the life and work of Lady Ada Lovelace and to promote women in technology.\n",
            "\n",
            "These initiatives and others continue to build on the foundation laid by Lady Ada Lovelace and inspire new generations of researchers, scientists, and engineers.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.workflow import Context\n",
        "\n",
        "# Remembering state\n",
        "ctx = Context(alfred)\n",
        "\n",
        "# First interaction\n",
        "response1 = await alfred.run(\"Tell me about Lady Ada Lovelace.\", ctx=ctx)\n",
        "print(\"ðŸŽ© Alfred's First Response:\")\n",
        "print(response1)\n",
        "\n",
        "# Second interaction (referencing the first)\n",
        "response2 = await alfred.run(\"What projects is she currently working on?\", ctx=ctx)\n",
        "print(\"ðŸŽ© Alfred's Second Response:\")\n",
        "print(response2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "076a8e45003e4132a18bf08d9518138d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_e529e833b8d543fc91c9329440dee8d5",
            "style": "IPY_MODEL_13b36eb2d29e41828372a86fbee846a2",
            "value": true
          }
        },
        "09204ab99deb43f08efda1deaa406fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "13b36eb2d29e41828372a86fbee846a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14aab21c71cf44b2b1d5081250fb51ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_36331b8488a743b0b6d8fc7e803cf779",
            "style": "IPY_MODEL_09204ab99deb43f08efda1deaa406fd8",
            "tooltip": ""
          }
        },
        "1b99d700258143388048f1616c427bef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22157d9f114c476d8c86777e988020c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36331b8488a743b0b6d8fc7e803cf779": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c43cd9dcd8411fafb977c6b3424802": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57d6c51282ff4750b15319ee9a5d804f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "596c48effc134d3fb9e91135a83e43ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3acd0c86ce24a9ea8a37c172c17af73",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_22157d9f114c476d8c86777e988020c9",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "70919a3277db41f4bf233944e6329178": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a88ccc0b5ee41539df9317c61c853d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_933f843d706f4603903f86850dcc2194"
          }
        },
        "933f843d706f4603903f86850dcc2194": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "b3111f59a568411aaf06945175d46321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1b99d700258143388048f1616c427bef",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_57d6c51282ff4750b15319ee9a5d804f",
            "value": ""
          }
        },
        "b9b52f099c3a48f5a97ee524507bdc0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2d2b07f4dc9442d8733b48b4d292100": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70919a3277db41f4bf233944e6329178",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d75b2bd76a89432da7e363fc2f84fd17",
            "value": "Connecting..."
          }
        },
        "d75b2bd76a89432da7e363fc2f84fd17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e529e833b8d543fc91c9329440dee8d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8876c95d71f4be1915718a7fec13f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42c43cd9dcd8411fafb977c6b3424802",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b9b52f099c3a48f5a97ee524507bdc0d",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "f3acd0c86ce24a9ea8a37c172c17af73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
